# 基本概念

| 名称 | RDB类比 | 说明 |
|---|---|---|
| 集群(cluster) | | 有至少一个节点组成，共同拥有完整的数据 |
| 节点(node) | 实例 | 单个进程，提供es服务并存储数据 |
| 索引(index) | 表(table) | 具有相似结构特性的文档集合 |
| Data streams | | 数据流，仅添加时序数据(如日志、指标等) |
| TSDS | | 时间序列数据流(time series data streams)，数据流`Data streams`的时间序列优化版本 |
| 别名(aliases) | 视图 | 可以管理一组索引或其部分文档 |
| 映射(Mapper) | schema | 定义文档结构说明 |
| 文档(documents) | 行 | 可被索引的基本信息单元 |
| 字段(field) | 列 | 定义文档的属性 |
| 分片(shards) | | 包含索引中一部分文档，所有分片构成整个索引的所有数据集 |
| Lucene Index | | Lucene索引，同分片 |
| Segment | | 单个倒排索引文件，多个`Segment`组成一个`Lucene Index` |
| Transaction Log | binlog | 日志文件，保证数据不丢失 |
| 副本(replicas) | | 分片的复制，与对应的分片拥有相同的数据以容灾，每个分片可有零到多个副本 |
| [Query DSL](Query%20DSL.md) | DQL | 查询语言，查询数据 |
| 倒排索引 | B+树 | ES的一种数据索引结构 |
| 索引模板 | | 定义一类索引的模板，显示创建索引无效 |
| 组件模板 | | 定义索引模板的模板 |
| 查询模板 | | 定义查询的模板，可使用参数进行查询 |
| Ingest Pipeline | | 采集管道，在索引前转换数据 |
| Processor | | 数据处理器，多个处理器按顺序组合成`Ingest Pipeline` |
| Painless | | 数据处理脚本, 新版本中脚本只支持`Painless` |
| Enrich policy | | 扩充策略，用于在`Ingest Pipeline`自动补充数据 |
| ILM | | 索引生命周期管理(index lifecycle manage) |
| repository | | 存储库，存储快照 |
| snapshot | | 快照，集群的备份。可不停机的备份集群，用以崩溃恢复、集群间传输数据 |
| searchable snapshot | | 可搜索快照，以较低存储开销保存不常读取的只读数据 |
| SLM | | 快照生命周期管理(snapshot lifecycle manage) |

---
# 节点
单个es进程，提供服务。

## 类型
每个节点可以成为其中的一个或多个类型。

1. 主节点(Master Node): 每个集群只有一个，负责处理集群操作。如: 创建删除索引、分配分片等。
2. 候选主节点(Master Eligible Node): 可成为主节点的节点。建议大于3个。
3. 数据节点(Data Node): 存储数据及索引的节点。
4. 索引预处理节点(Ingest Node): (默认关闭)预处理数据。如管道操作。
5. 协调节点(Coordinating Node): (默认关闭)仅负责转发请求，实现负载均衡。不会成为主节点(候选主节点)和数据节点。

# 索引 & 数据流 & 时间序列
- 索引: 通用文档集合
- 数据流: 一组仅添加的索引集合，根据`索引模板`自动创建索引及使用`ILM`。模板中添加`data_stream`配置(内容为`{}`即可)及`settings.index.lifecycle.name`配置
- 时间序列: 基于时间序列优化版`数据流`，减少磁盘使用。`template.settings.index.mode`需设置为`time_series`；需要包含`date`类型的`@timestamp`字段，其他字段为维度(`keyword`类型且`time_series_dimension`为`true`)

# Lucene Index
Lucene索引，每个Lucene索引即为一个索引的分片。

数据写入流程:
1. 文档写入`Index Buffer`(内存)及`Transaction Log`(落盘)
2. 默认`Index Buffer`写满或每秒执行一次`refresh`, 将`Index Buffer`写入`Segment`
3. 默认`Transaction Log`写满(默认512MB)或每30分钟执行`flush`，调用一次`refresh`并将`Segment`写入磁盘及清空`Transaction Log`
4. 定期或手动调用执行`merge`, 将`Segment`文件合并及删除已删除的文档

# 查询流程
1. `Query`: 查询阶段，从每个副本阶段查询数据的`id`及排序值。类似`Map`
2. `Fetch`: 合并阶段，将每个副本查询到的数据合并为需要的数据`id`，并从副本中查询该文档。类似`Reduce`

# Ingest Pipeline
对数据进行预处理。拦截请求、转换数据、设置默认值、重命名、切分字段等。

由多个`Processor`组成，每个`Processor`为处理的其中一个步骤。

![](https://www.elastic.co/guide/en/elasticsearch/reference/current/images/ingest/ingest-process.svg)

# ILM
ILM(index life manage)索引生命周期管理，根据策略管理索引的生命周期。
分为以下阶段:
1. Hot: 热，可被频繁更新查询
2. Warm: 暖，不被更新，可查询
3. Cold: 冷，不被更新，少量查询
4. Frozen: 冻结，不被更新，极少查询
5. Delete: 删除