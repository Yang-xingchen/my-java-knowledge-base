# 基本概念

| 名称 | RDB类比 | 说明 |
|---|---|---|
| 集群(cluster) | | 有至少一个节点组成，共同拥有完整的数据 |
| 节点(node) | 实例 | 单个进程，提供es服务并存储数据 |
| 索引(index) | 表(table) | 具有相似结构特性的文档集合 |
| 别名(aliases) | 视图 | 可以管理一组索引或其部分文档 |
| 映射(Mapper) | schema | 定义文档结构说明 |
| 文档(documents) | 行 | 可被索引的基本信息单元 |
| 字段(field) | 列 | 定义文档的属性 |
| 分片(shards) | | 包含索引中一部分文档，所有分片构成整个索引的所有数据集 |
| Lucene Index | | Lucene索引，同分片 |
| Segment | | 单个倒排索引文件，多个`Segment`组成一个`Lucene Index` |
| Transaction Log | binlog | 日志文件，保证数据不丢失 |
| 副本(replicas) | | 分片的复制，与对应的分片拥有相同的数据以容灾，每个分片可有零到多个副本 |
| [Query DSL](Query%20DSL.md) | DQL | 查询语言，查询数据 |
| 倒排索引 | B+树 | ES的一种数据索引结构 |
| 索引模板 | | 定义一类索引的模板，显示创建索引无效 |
| 组件模板 | | 定义索引模板的模板 |
| 查询模板 | | 定义查询的模板，可使用参数进行查询 |
| Ingest Pipeline | | 对数据进行预处理 |
| Processor | | 数据处理器，多个处理器按顺序组合成`Ingest Pipeline` |
| Painless | | 数据处理脚本, 新版本中脚本只支持`Painless` |
| Enrich policy | | 丰富策略，用于在`Ingest Pipeline`自动补充数据 |

---
# 节点
单个es进程，提供服务。

## 类型
每个节点可以成为其中的一个或多个类型。

1. 主节点(Master Node): 每个集群只有一个，负责处理集群操作。如: 创建删除索引、分配分片等。
2. 候选主节点(Master Eligible Node): 可成为主节点的节点。建议大于3个。
3. 数据节点(Data Node): 存储数据及索引的节点。
4. 索引预处理节点(Ingest Node): (默认关闭)预处理数据。如管道操作。
5. 协调节点(Coordinating Node): (默认关闭)仅负责转发请求，实现负载均衡。不会成为主节点(候选主节点)和数据节点。

# Lucene Index
Lucene索引，每个Lucene索引即为一个索引的分片。

数据写入流程:
1. 文档写入`Index Buffer`(内存)及`Transaction Log`(落盘)
2. 默认`Index Buffer`写满或每秒执行一次`refresh`, 将`Index Buffer`写入`Segment`
3. 默认`Transaction Log`写满(默认512MB)或每30分钟执行`flush`，调用一次`refresh`并将`Segment`写入磁盘及清空`Transaction Log`
4. 定期或手动调用执行`merge`, 将`Segment`文件合并及删除已删除的文档

# 查询流程
1. `Query`: 查询阶段，从每个副本阶段查询数据的`id`及排序值。类似`Map`
2. `Fetch`: 合并阶段，将每个副本查询到的数据合并为需要的数据`id`，并从副本中查询该文档。类似`Reduce`

# Ingest Pipeline
对数据进行预处理。拦截请求、转换数据、设置默认值、重命名、切分字段等。

由多个`Processor`组成，每个`Processor`为处理的其中一个步骤。

![](https://www.elastic.co/guide/en/elasticsearch/reference/current/images/ingest/ingest-process.svg)

## Processor
每个处理器处理一个步骤